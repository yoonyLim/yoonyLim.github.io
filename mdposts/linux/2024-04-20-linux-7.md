---
title: "리눅스로 한 학기 살기 7주차"
subtitle: "FFmpeg 멀티미디어 프레임워크 설치"
date: "2024-04-20"
---

# [리눅스] 리눅스로 한 학기 살기 - 7주차: FFmpeg 멀티미디어 프레임워크 설치

## 1. 개요

### 1.1 사전 배경

FFmpeg는 소프트웨어로서는 일부 기능의 GPL 혹은 다른 기능들의 LGPL 라이선스로의 오픈 소스 멀티미디어 프레임워크이다. 언뜻 듣기에는 특별한 소프트웨어로 보이지는 않지만 FFmpeg는 코덱 및 멀티미디어 재생을 지원하는 소프트웨어의 표준이라 불릴 수 있을 만큼 막대한 영향력을 가지고 있다. 예시로 영상을 압축하는 기술인 HEVC(High Efficiency Video Coding)의 H.265 버전이 유료 버전으로서 FFmpeg에 포함되자 구글, 모질라, 시스코, 아마존, 애플, ARM, 페이스북, 넷플릭스, 엔비디아, 삼성, 텐센트 등의 전세계 IT 기업들이 로열티 문제를 피하고자 AV1(Alliance for Open Media Video 1)이라는 코덱을 개발하여 FFmpeg에 제공했다.<sup>[1)](#ref1)</sup><sup>[2)](#ref2)</sup> 

FFmpeg 프로젝트는 2000년 프랑스의 프로그래머 Fabrice Bellard에 의해 시작됐으며 목적은 다양한 라이브러리를 지원하여 오디오 및 동영상 파일들의 처리하는 것이었다.<sup>[3)](#ref3)</sup> Fabrice Bellard가 FFmpeg 외로도 파이를 기존보다 더 빠르게 16진법으로 구할 수 있는 Bellard's formula를 발표하거나 현재 대부분의 가상 머신에서 쓰이는 컴퓨터 프로세서의 바이너리를 에뮬레이트하는 QEMU의 개발, 3 kB의 컴파일러로 유명한 Tiny C Compiler 등의 개발로도 유명하다.

현재 FFmpeg은 커맨드라인으로 사용 가능한 소프트웨어로서 GUI만 제공한다면 타 동영상 편집 프로그램이 제공하는 대부분의 기능을 손쉽게 사용하도록 만들 수도 있다.

### 1.2 수행 요약

본인은 FFmpeg를 아치 리눅스에 설치한 뒤 명령어를 사용하여 본인이 편집하고자 하는 동영상들을 자르고 이어 붙였다. 해당 과정을 익숙한 GUI가 아닌 CLI 환경으로 진행하며 사용자의 경험에서의 GUI의 편의성과 CLi의 간결성 간 간극을 체험할 수 있었다.

## 2. FFmpeg 설치

FFmpeg의 설치는 아치 리눅스의 패키지 매니저 pacman을 사용하여 아래와 같은 명령어로 손쉽게 설치할 수 있다:

```bash
sudo pacman -S ffmpeg
```

## 3 FFmpeg 사용법

### 3.1 FFmpeg 명령어 목록

모든 FFmpeg의 명령어는 [다큐멘테이션 사이트](https://ffmpeg.org/ffmpeg.html)에서 살펴볼 수 있다. 그러나 본 포스트에서는 개인용으로 쓰기 위해 다른 동영상 편집기에서 쓰이는 기능들을 FFmpeg에서 어떻게 쓸 수 있는지 살펴보고자 한다.

우선 명령어는 옵션들을 지정함으로 완성된다. 아래는 자주 쓰이는 옵션들이다:
- "-i": 입력되는 파일 지정
- "-f": 입력/출력되는 파일의 포맷을 지정
- "-c": 동영상의 코덱 형식 지정("copy"로 지정 시 원본과 같은 코덱 유지)
- "-filter_complex": 복잡한 필터 적용 (한 미디어 위에 다른 미디어의 오버레이, 지정된 시간대의 트랜지션 적용 등)

위 명령어들을 활용하여 아래와 같은 기본적인 동영상 편집이 가능하다.

1. 자르기:

```bash
ffmpeg -i [입력 영상] -ss [시작 타임스탬프] -to [끝나는 타임스탬프] [출력 영상]
```

2. 같은 시간대로 분할: 

- "-acodec": 오디오의 코덱 형식 지정("copy"로 지정 시 원본과 같은 코덱 유지)
- "-vcodec": 동영상의 코덱 형식 지정("copy"로 지정 시 원본과 같은 코덱 유지)
- "reset_timestmps": 각 세그먼트가 연속되는지 여부 지정
- "-map": 생성되는 스트림 당 출력 방식 지정
- "_%d": "-map"을 통해 생성되는 같은 길이의 영상들마다 인덱스 부여

```bash
ffmpeg -i [입력 영상] -acodec copy -f segment -segment_time [자르는 세그먼트 당 시간] -vcodec copy -reset_timestamps 1 -map 0 [출력 영상]_%d.[영상 형식]
```

3. 합치기:

동영상을 합칠 때는 텍스트 파일을 이용하여 합치고자 하는 동영상들을 목록으로 나열한 뒤 명령어를 실행하게 된다.

```
# 텍스트 파일
file "[영상 파일 1]"
file "[영상 파일 2]"
...[이 외로 합칠 영상 파일 목록]
```

```bash
ffmpeg -f concat -i [텍스트 파일] -c copy [출력 영상]
```

4. Picture in Picture:

아래는 두번째로 오는 입력 영상을 1/5 크기로 만든 다음 첫번째 영상 위에 picture-in-picture로 오버레이할 수 있도록 하는 명령어이다. 해상도는 720x400으로 맞추었다. "overlay" 뒤에 다른 너비 및 높이 크기를 줌으로 상단 왼/오른쪽, 하단 왼/오른쪽 혹은 어느 특정 위치에 오버레이할 수 있다.

```bash
ffmpeg -i [입력 영상 1] -i [입력 영상 2] -filter_complex "[1]scale=iw/5:ih/5 [pip]; [0][pip] overlay=main_w-overlay_w-10:10" -profile:v main -level 3.1 -b:v 440k -ar 44100 -ab 128k -s 720x400 -vcodec h264 -acodec copy [출력 영상]
```

5. Transition:

FFmpeg는 xfade 라이브러리를 사용하여 영상 내 트랜지션도 지원하고 있다.<sup>[4)](#ref4)</sup> 해당 다큐멘테이션에 따라 트랜지션 종류를 명시하여 두 영상을 합치는 것도 가능하다.

```bash
ffmpeg -i [입력 영상 1] -i [입력 영상 2] -filter_complex xfade=transition=[트랜지션 종류]:duration=[트랜지션 길이]:offset=[트랜지션 시작 시간] [출력 영상]
```

### 3.2 FFmpeg 명령어를 사용한 예시

위의 명령어들을 사용하여 직접 아래의 영상들을 사용하여 편집을 시도했다.

<video autoplay loop controls>
  <source src="https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/c58e3b23-80ec-4b3d-b25a-84493e410052" type="video/mp4">
</video>
*sample1.mp4*

<video width="720" autoplay loop controls>
  <source src="https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/bf1eee30-73d3-43d9-aae8-c25c7278639d" type="video/mp4">
</video>
*sample2.mp4*

1. 자르기:

```bash
ffmpeg -i sample1.mp4 -ss 10:00 -to 20:00 split_output.mp4
```

<video autoplay loop controls>
  <source src="https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/f8ea38ea-7c66-42c8-9b43-08901201e083" type="video/mp4">
</video>
*결과인 split_output.mp4*

2. Picture in Picture

아래는 두 영상을 picture-in-picture로 합쳐서 10초짜리 영상을 만든 명령어이다.

```bash
ffmpeg -i sample1.mp4 -i sample2.mp4 -filter_complex "[1]scale=iw/5:ih/5 [pip]; [0][pip] overlay=main_w-overlay_w-10:10" -profile:v main -level 3.1 -b:v 440k -ar 44100 -ab 128k -vcodec h264 -acodec copy -t 10 pip_output.mp4
```

<video autoplay loop controls>
  <source src="https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/ce450d3b-eebf-49e4-a34a-94b30eceab0e" type="video/mp4">
</video>
*결과인 pip_output.mp4*

3. Transition

아래는 sample1.mp4를 이용하여 트랜지션을 넣어 20초짜리 영상을 만든 명령어이다.

```bash
ffmpeg -i sample1.mp4 -i sample1.mp4 -filter_complex xfade=transition=fade:duration=2:offset=8 -t 20 transition_output.mp4
```

https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/1647adb4-03a6-4530-8c46-0ea34055919e

<video autoplay loop controls>
  <source src="https://github.com/yoonyLim/yoonyLim.github.io/assets/64838255/1647adb4-03a6-4530-8c46-0ea34055919e" type="video/mp4">
</video>
*결과인 transition_output.mp4*

### 3.3 FFmpeg 사용 경험

일단 FFmpeg 자체가 커맨드를 사용하여 동영상 인코딩/디코딩 및 편집하는 멀티미디어 프레임워크다 보니 일반 동영상 편집기와 비교하면 매우 설정하기가 까다롭고 하나의 기능을 넣으려 해도 익숙치 않은 사용자라면 많이 헤매게 된다. 또한 각 영상들의 해상도나 코덱이 맞지 않다면 합쳐지지 않는 것도 직접 코덱을 설정하여 해결해야 하는 번거로움이 존재한다.

그렇지만 일반 동영상 편집기보다도 폭넓은 자유를 제공한다는 것은 큰 장점이다. 본인이 원하는 코덱으로 길이를 자유자재로 늘려 오디오 및 동영상 파일의 편집이 원하는 방식대로 가능하니 오직 존재하는 한계점은 다큐멘테이션에 대한 이해도와 사용 경험 외로는 없다. 따라서 FFmpeg를 응용하여 GUI를 만들어 쓰기 편하게 만든 프로젝트들도 존재하며 다른 동영상 편집 소프트웨어에 뒤지지 않는 편의성을 제공할 수도 있다.

## 4. References

<a id="ref1"></a>
1. CDNetworks, ["압축 표준 설명: VP9, AV1, H.266, H.265, H.264"](https://www.cdnetworks.com/ko/media-delivery-blog/compression-standards-explained/), 2023년 9월 27일.
<a id="ref2"></a>
2. Alliance for Open Media, ["About"](https://aomedia.org/about/).
<a id="ref3"></a>
3. Cloudinary, ["FFmpeg"](https://cloudinary.com/glossary/ffmpeg).
<a id="ref4"></a>
4. FFmpeg, ["Xfade"](https://trac.ffmpeg.org/wiki/Xfade).
